
import os
import requests
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
SEARCH_API_KEY = os.environ.get("SEARCH_API_KEY")
SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID")

def get_page_text_with_selenium(url):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-software-rasterizer")
    options.binary_location = "/usr/bin/chromium-browser"
    driver = webdriver.Chrome(options=options)
    try:
        driver.get(url)
        time.sleep(3)
        paragraphs = driver.find_elements(By.TAG_NAME, "p")
        text = "\n".join([p.text for p in paragraphs])
        short_text = text.strip()[:4000]
        print("$D83D$DCC4 å–å¾—ã—ãŸæœ¬æ–‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­200æ–‡å­—ï¼‰:")
        print(short_text[:200] + "..." if len(short_text) > 200 else short_text)
        return short_text
    except Exception as e:
        print(f"âš ï¸ Seleniumå–å¾—å¤±æ•—: {e}")
        return ""
    finally:
        driver.quit()

def detect_emotion(comment):
    prompt = f"ä»¥ä¸‹ã®æ—¥æœ¬èªã®æ–‡ã‹ã‚‰ã€æ„Ÿæƒ…ã‚’1å˜èªã§è‹±èªã§åˆ†é¡ã—ã¦ãã ã•ã„ï¼ˆhappy, angry, sad, surprised, confused, love, neutralã®ã„ãšã‚Œã‹ï¼‰ã€‚æ„Ÿæƒ…åã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n\"{comment}\""
    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        emotion = res.choices[0].message.content.strip().lower()
        return emotion if emotion in ["happy", "angry", "sad", "surprised", "confused", "love", "neutral"] else "neutral"
    except Exception as e:
        print(f"âš ï¸ æ„Ÿæƒ…åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—: {e}")
        return "neutral"

def translate_title_to_japanese(title):
    res = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f"ä»¥ä¸‹ã®è‹±èªã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{title}"}]
    )
    return res.choices[0].message.content.strip()

def generate_summary_comment(text):
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ã‚„ã•ã—ãã¦ã¡ã‚‡ã£ã´ã‚Šãƒ„ãƒ³ãƒ‡ãƒ¬ãªAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": f"ä»¥ä¸‹ã®æ—¥æœ¬èªè¨˜äº‹æœ¬æ–‡ã‚’èª­ã‚“ã§ã€æœ€å¾Œã«ã€å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚ã€ã¨ã—ã¦ç´„400æ–‡å­—ã§æœ¬è³ªçš„ãªå†…å®¹ã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚\n\n{text}"}
        ]
    )
    return res.choices[0].message.content.strip()

def rewrite_with_comments(text):
    prompt = f"""
ä»¥ä¸‹ã¯è‹±èªã®ã‚¦ã‚§ãƒ–è¨˜äº‹æœ¬æ–‡ã§ã™ã€‚ã“ã‚Œã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«æ—¥æœ¬èªã§å¤‰æ›ã—ã¦ãã ã•ã„ï¼š

ã€å¤‰æ›ãƒ«ãƒ¼ãƒ«ã€‘
1. å…¨ä½“ã‚’è¦ç´„ã›ãšã€1ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãšã¤ä¸å¯§ã«ç¿»è¨³ãƒ»è¨€ã„æ›ãˆã¦ãã ã•ã„ã€‚
2. å„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ç›´å¾Œã«ã€ŒAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã€ã¨ã—ã¦ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’1æ–‡æŒ¿å…¥ã—ã¦ãã ã•ã„ã€‚
3. ã‚³ãƒ¡ãƒ³ãƒˆã®å‰ã«ã¯å¿…ãšã€Œ> ğŸ’¬ ã€ã¨ã„ã†è¨˜å·ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
4. ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚„ã‚„ãƒ„ãƒ³ãƒ‡ãƒ¬æ°—å‘³ã§ã€ã‹ã‚ã„ãã¦é¢å€’è¦‹ãŒè‰¯ãã€å„ªã—ã„æ„Ÿã˜ã«ã—ã¦ãã ã•ã„ã€‚
5. ã‚³ãƒ¡ãƒ³ãƒˆã¯é‹­ãæœ¬è³ªã‚’çªãã“ã¨ã‚‚ã‚ã‚‹ãŒã€æ ¹æœ¬çš„ã«ã¯åŠ±ã¾ã—ãƒ»å…±æ„Ÿãƒ»å„ªã—ã•ã®ã‚ã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
6. å…¨ä½“ã¯å­¦ç´šå§”å“¡é•·ã‚­ãƒ£ãƒ©ãŒè¨˜äº‹ã‚’èª­ã‚“ã§ã„ã‚‹ã‚ˆã†ãªå£èª¿ã¨é›°å›²æ°—ã«ã—ã¦ãã ã•ã„ã€‚
"""
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ãƒ¡ã‚¬ãƒã®é»’é«ªãƒãƒ‹ãƒ¼ãƒ†ãƒ¼ãƒ«ã®AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": prompt + "\n\n--- è‹±æ–‡æœ¬æ–‡ ---\n" + text + "\n--- ã“ã“ã¾ã§ ---"}
        ]
    )
    return res.choices[0].message.content.strip()

def format_comment_block(comment, emotion):
    return f'''
<div style="display: flex; align-items: flex-start; margin: 1em 0;">
  <div style="background: #fceefc; border: 2px solid #ffaad4; border-radius: 12px; padding: 10px 14px; max-width: 75%; font-family: 'Hiragino Maru Gothic ProN', sans-serif;">
    ğŸ’¬ {comment}
  </div>
  <img src="https://zin1985.github.io/ai_news_blogger/images/{emotion}.png" alt="{emotion}" style="width: 100px; margin-left: 10px;">
</div>
'''

def insert_html_wrappers(title, url, body):
    lines = body.splitlines()
    new_lines = []
    for line in lines:
        if line.startswith("> ğŸ’¬"):
            comment = line.replace("> ğŸ’¬", "").strip()
            emotion = detect_emotion(comment)
            new_lines.append(format_comment_block(comment, emotion))
        else:
            new_lines.append(f"<p>{line}</p>")
    summary = generate_summary_comment(body)
    new_lines.insert(0, f"<p>ã“ã‚“ã«ã¡ã¯ã€AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ãŒä»Šæ—¥ã‚‚ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹ã­â™ª</p>")
    new_lines.insert(1, f"<p><strong>å…ƒè¨˜äº‹URLï¼š</strong> <a href='{url}' target='_blank'>{url}</a></p>")
    new_lines.append(f"<h3>å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚</h3>")
    new_lines.append(f"<p>{summary}</p>")
    return "\n".join(new_lines)

def get_latest_ai_news():
    query = "OpenAI FDA AI site:reuters.com OR site:cnn.com OR site:nytimes.com OR site:bbc.com"
    url = f"https://www.googleapis.com/customsearch/v1?key={SEARCH_API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}"

    try:
        res = requests.get(url)
        res.raise_for_status()
        items = res.json().get("items", [])
    except Exception as e:
        print(f"$274C Search APIå¤±æ•—: {e}")
        return []

    articles = []
    for item in items:
        title_en = item["title"]
        article_url = item["link"]
        print(f"$D83D$DD17 URLå–å¾—: {article_url}")
        full_text = get_page_text_with_selenium(article_url)
        if not full_text or len(full_text) < 300:
            print(f"âš ï¸ ç„¡åŠ¹ã¾ãŸã¯çŸ­ã™ãã‚‹ãƒšãƒ¼ã‚¸: {article_url}")
            continue
    
        rewritten = rewrite_with_comments(full_text)
        wrapped = insert_html_wrappers(title_en, article_url, rewritten)
        title_ja = translate_title_to_japanese(title_en)
        final_title = f"ã€{title_ja}ã€ã‚’å§”å“¡é•·ã¡ã‚ƒã‚“ãŒè§£èª¬â™ª"
        articles.append({
            "title": final_title,
            "url": article_url,
            "content": wrapped
        })
        break  # æœ€åˆã«æœ‰åŠ¹ãªè¨˜äº‹ã‚’è¦‹ã¤ã‘ãŸã‚‰ãƒ«ãƒ¼ãƒ—çµ‚äº†
    return articles
