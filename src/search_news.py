
import os
import requests
import time
import tempfile
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
SEARCH_API_KEY = os.environ.get("SEARCH_API_KEY")
SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID")

def get_page_text_with_selenium(url):
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    import time
    import traceback

    options = Options()
    options.add_argument("--headless")  # â† new ã§è½ã¡ã‚‹å ´åˆã¯ old headless ã«å¤‰æ›´
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")

    driver = None
    try:
        print("ğŸ”§ STEP 1: Creating Chrome WebDriver instance...")
        driver = webdriver.Chrome(options=options)
        print("âœ… STEP 1 OK: Chrome WebDriver started")

        print(f"ğŸ”§ STEP 2: Navigating to URL: {url}")
        driver.get(url)
        print("âœ… STEP 2 OK: Page loaded")

        print("ğŸ”§ STEP 3: Waiting for <p> elements...")
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "p"))
        )

        print("ğŸ”§ STEP 4: Extracting text from <p> elements...")
        paragraphs = driver.find_elements(By.TAG_NAME, "p")
        text = "\n".join([p.text for p in paragraphs if p.text.strip()])
        print(f"ğŸ§¾ æŠ½å‡ºæ–‡å­—æ•°: {len(text)}\n{text[:300]}...")
        return text.strip()[:4000]

    except Exception as e:
        print("âš ï¸ Seleniumå–å¾—å¤±æ•—ï¼ˆä¾‹å¤–ç™ºç”Ÿï¼‰:")
        traceback.print_exc()
        return ""

    finally:
        if driver:
            try:
                print("ğŸ”§ STEP 5: Quitting Chrome WebDriver...")
                driver.quit()
                print("âœ… STEP 5 OK: Chrome WebDriver quit")
            except Exception as quit_err:
                print(f"âš ï¸ driver.quit() ã§ã‚¨ãƒ©ãƒ¼: {quit_err}")

def detect_emotion(comment):
    prompt = f"ä»¥ä¸‹ã®æ—¥æœ¬èªã®æ–‡ã‹ã‚‰ã€æ„Ÿæƒ…ã‚’1å˜èªã§è‹±èªã§åˆ†é¡ã—ã¦ãã ã•ã„ï¼ˆhappy, angry, sad, surprised, confused, love, neutralã®ã„ãšã‚Œã‹ï¼‰ã€‚æ„Ÿæƒ…åã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n\"{comment}\""
    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        emotion = res.choices[0].message.content.strip().lower()
        return emotion if emotion in ["happy", "angry", "sad", "surprised", "confused", "love", "neutral"] else "neutral"
    except Exception as e:
        print(f"$26A0$FE0F æ„Ÿæƒ…åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—: {e}")
        return "neutral"

def translate_title_to_japanese(title):
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": f"ä»¥ä¸‹ã®è‹±èªã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{title}"}]
    )
    return res.choices[0].message.content.strip()

def generate_summary_comment(text):
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ã‚„ã•ã—ãã¦ã¡ã‚‡ã£ã´ã‚Šãƒ„ãƒ³ãƒ‡ãƒ¬ãªAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": f"ä»¥ä¸‹ã®æ—¥æœ¬èªè¨˜äº‹æœ¬æ–‡ã‚’èª­ã‚“ã§ã€æœ€å¾Œã«ã€å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚ã€ã¨ã—ã¦ç´„400æ–‡å­—ã§ã‹ã‚ã„ãç· ã‚ããã£ã¦ãã ã•ã„ã€‚\n\n{text}"}
        ]
    )
    return res.choices[0].message.content.strip()

def rewrite_with_comments(text):
    prompt = f"""
ä»¥ä¸‹ã¯è‹±èªã®ã‚¦ã‚§ãƒ–è¨˜äº‹æœ¬æ–‡ã§ã™ã€‚ã“ã‚Œã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«æ—¥æœ¬èªã§å¤‰æ›ã—ã¦ãã ã•ã„ï¼š

ã€å¤‰æ›ãƒ«ãƒ¼ãƒ«ã€‘
1. å…¨ä½“ã‚’è¦ç´„ã›ãšã€1ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãšã¤ä¸å¯§ã«ç¿»è¨³ãƒ»è¨€ã„æ›ãˆã¦ãã ã•ã„ã€‚
2. å„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ç›´å¾Œã«ã€ŒAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã€ã¨ã—ã¦ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’1æ–‡æŒ¿å…¥ã—ã¦ãã ã•ã„ã€‚
3. ã‚³ãƒ¡ãƒ³ãƒˆã®å‰ã«ã¯å¿…ãšã€Œ> $D83D$DCAC ã€ã¨ã„ã†è¨˜å·ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
4. ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚„ã‚„ãƒ„ãƒ³ãƒ‡ãƒ¬æ°—å‘³ã§ã€ã‹ã‚ã„ãã¦é¢å€’è¦‹ãŒè‰¯ãã€å„ªã—ã„æ„Ÿã˜ã«ã—ã¦ãã ã•ã„ã€‚
5. ã‚³ãƒ¡ãƒ³ãƒˆã¯é‹­ãæœ¬è³ªã‚’çªãã“ã¨ã‚‚ã‚ã‚‹ãŒã€æ ¹æœ¬çš„ã«ã¯åŠ±ã¾ã—ãƒ»å…±æ„Ÿãƒ»å„ªã—ã•ã®ã‚ã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
6. å…¨ä½“ã¯å­¦ç´šå§”å“¡é•·ã‚­ãƒ£ãƒ©ãŒè¨˜äº‹ã‚’èª­ã‚“ã§ã„ã‚‹ã‚ˆã†ãªå£èª¿ã¨é›°å›²æ°—ã«ã—ã¦ãã ã•ã„ã€‚
"""
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ãƒ¡ã‚¬ãƒã®é»’é«ªãƒãƒ‹ãƒ¼ãƒ†ãƒ¼ãƒ«ã®AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": prompt + "\n\n--- è‹±æ–‡æœ¬æ–‡ ---\n" + text + "\n--- ã“ã“ã¾ã§ ---"}
        ]
    )
    return res.choices[0].message.content.strip()

def format_comment_block(comment, emotion):
    return f'''
<div style="display: flex; align-items: flex-start; margin: 1em 0;">
  <div style="background: #fceefc; border: 2px solid #ffaad4; border-radius: 12px; padding: 10px 14px; max-width: 75%; font-family: 'Hiragino Maru Gothic ProN', sans-serif;">
    $D83D$DCAC {comment}
  </div>
  <img src="https://zin1985.github.io/ai_news_blogger/images/{emotion}.png" alt="{emotion}" style="width: 100px; margin-left: 10px;">
</div>
'''

def insert_html_wrappers(title, url, body):
    lines = body.splitlines()
    new_lines = []
    for line in lines:
        if line.startswith("> $D83D$DCAC"):
            comment = line.replace("> $D83D$DCAC", "").strip()
            emotion = detect_emotion(comment)
            new_lines.append(format_comment_block(comment, emotion))
        else:
            new_lines.append(f"<p>{line}</p>")
    summary = generate_summary_comment(body)
    new_lines.insert(0, f"<p>ã“ã‚“ã«ã¡ã¯ã€AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ãŒä»Šæ—¥ã‚‚ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹ã­â™ª</p>")
    new_lines.insert(1, f"<p><strong>å…ƒè¨˜äº‹URLï¼š</strong> <a href='{url}' target='_blank'>{url}</a></p>")
    new_lines.append(f"<h3>å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚</h3>")
    new_lines.append(f"<p>{summary}</p>")
    return "\n".join(new_lines)

def get_latest_ai_news():
    query = "OpenAI FDA AI site:reuters.com OR site:cnn.com OR site:nytimes.com OR site:bbc.com"
    url = f"https://www.googleapis.com/customsearch/v1?key={SEARCH_API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}"

    try:
        res = requests.get(url)
        res.raise_for_status()
        items = res.json().get("items", [])
    except Exception as e:
        print(f"âŒ Search APIå¤±æ•—: {e}")
        return []

    articles = []
    for item in items[:10]:
        title_en = item["title"]
        article_url = item["link"]
        print(f"ğŸ”— URLå–å¾—: {article_url}")
        full_text = get_page_text_with_selenium(article_url)
        print(f"ğŸ”— æœ¬æ–‡å–å¾—: {full_text}")
        if not full_text or len(full_text) < 300:
            print(f"âš ï¸ ç„¡åŠ¹ã¾ãŸã¯çŸ­ã™ãã‚‹ãƒšãƒ¼ã‚¸: {article_url}")
            continue
        rewritten = rewrite_with_comments(full_text)
        wrapped = insert_html_wrappers(title_en, article_url, rewritten)
        title_ja = translate_title_to_japanese(title_en)
        final_title = f"ã€{title_ja}ã€ã‚’å§”å“¡é•·ã¡ã‚ƒã‚“ãŒè§£èª¬â™ª"
        articles.append({
            "title": final_title,
            "url": article_url,
            "content": wrapped
        })

    return articles
