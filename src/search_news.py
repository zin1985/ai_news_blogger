
import os
import requests
import time
import tempfile
import json
import random
from openai import OpenAI
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
SEARCH_API_KEY = os.environ.get("SEARCH_API_KEY")
SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID")

def get_page_text_with_playwright(url):
    print(f"ğŸŒ [Playwright] ã‚¢ã‚¯ã‚»ã‚¹é–‹å§‹: {url}")
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)

            # âœ… ãƒ¢ãƒã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶é¢¨ã®ç’°å¢ƒã‚’æ§‹ç¯‰ï¼ˆUAå½è£…ï¼‹viewportæŒ‡å®šï¼‹is_mobileï¼‰
            context = browser.new_context(
                user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) "
                           "AppleWebKit/605.1.15 (KHTML, like Gecko) "
                           "Version/16.0 Mobile/15E148 Safari/604.1",
                viewport={"width": 375, "height": 667},
                is_mobile=True,
                device_scale_factor=2
            )

            page = context.new_page()
            page.goto(url, timeout=60000)
            page.wait_for_timeout(5000)  # JSæç”»ã®ä½™è£•ã‚’ç¢ºä¿

            # âœ… ãƒ¢ãƒã‚¤ãƒ«è¡¨ç¤ºã§ã¯ body ã® inner_text ã‚’ã¾ã‚‹ã”ã¨å–å¾—
            content = page.inner_text("body")
            print(f"ğŸ§¾ æŠ½å‡ºæ–‡å­—æ•°: {len(content)}\n{content[:300]}...")
            browser.close()
            return content.strip()[:4000]

    except Exception as e:
        print(f"âš ï¸ Playwrightå–å¾—å¤±æ•—: {e}")
        return ""

def detect_emotion(comment):
    prompt = f"ä»¥ä¸‹ã®æ—¥æœ¬èªã®æ–‡ã‹ã‚‰ã€æ„Ÿæƒ…ã‚’1å˜èªã§è‹±èªã§åˆ†é¡ã—ã¦ãã ã•ã„ï¼ˆhappy, angry, sad, surprised, confused, love, neutralã®ã„ãšã‚Œã‹ï¼‰ã€‚æ„Ÿæƒ…åã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n\n\"{comment}\""
    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        emotion = res.choices[0].message.content.strip().lower()
        return emotion if emotion in ["happy", "angry", "sad", "surprised", "confused", "love", "neutral"] else "neutral"
    except Exception as e:
        print(f"$26A0$FE0F æ„Ÿæƒ…åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—: {e}")
        return "neutral"

def translate_title_to_japanese(title):
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": f"ä»¥ä¸‹ã®è‹±èªã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{title}"}]
    )
    return res.choices[0].message.content.strip()

def generate_summary_comment(text):
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ã‚„ã•ã—ãã¦ã¡ã‚‡ã£ã´ã‚Šãƒ„ãƒ³ãƒ‡ãƒ¬ãªAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": f"ä»¥ä¸‹ã®æ—¥æœ¬èªè¨˜äº‹æœ¬æ–‡ã‚’èª­ã‚“ã§ã€æœ€å¾Œã«ã€å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚ã€ã¨ã—ã¦ç´„400æ–‡å­—ã§ã‹ã‚ã„ãç· ã‚ããã£ã¦ãã ã•ã„ã€‚\n\n{text}"}
        ]
    )
    return res.choices[0].message.content.strip()

def rewrite_with_comments(text):
    prompt = f"""
ä»¥ä¸‹ã¯è‹±èªã®ã‚¦ã‚§ãƒ–è¨˜äº‹æœ¬æ–‡ã§ã™ã€‚ã“ã‚Œã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«æ—¥æœ¬èªã§å¤‰æ›ã—ã¦ãã ã•ã„ï¼š

ã€å¤‰æ›ãƒ«ãƒ¼ãƒ«ã€‘
1. å…¨ä½“ã‚’è¦ç´„ã›ãšã€1ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãšã¤ä¸å¯§ã«ç¿»è¨³ãƒ»è¨€ã„æ›ãˆã¦ãã ã•ã„ã€‚
2. å„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ç›´å¾Œã«ã€ŒAIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã€ã¨ã—ã¦ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’1æ–‡æŒ¿å…¥ã—ã¦ãã ã•ã„ã€‚
3. ã‚³ãƒ¡ãƒ³ãƒˆã®å‰ã«ã¯å¿…ãšã€Œ> $D83D$DCAC ã€ã¨ã„ã†è¨˜å·ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
4. ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚„ã‚„ãƒ„ãƒ³ãƒ‡ãƒ¬æ°—å‘³ã§ã€ã‹ã‚ã„ãã¦é¢å€’è¦‹ãŒè‰¯ãã€å„ªã—ã„æ„Ÿã˜ã«ã—ã¦ãã ã•ã„ã€‚
5. ã‚³ãƒ¡ãƒ³ãƒˆã¯é‹­ãæœ¬è³ªã‚’çªãã“ã¨ã‚‚ã‚ã‚‹ãŒã€æ ¹æœ¬çš„ã«ã¯åŠ±ã¾ã—ãƒ»å…±æ„Ÿãƒ»å„ªã—ã•ã®ã‚ã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
6. å…¨ä½“ã¯å­¦ç´šå§”å“¡é•·ã‚­ãƒ£ãƒ©ãŒè¨˜äº‹ã‚’èª­ã‚“ã§ã„ã‚‹ã‚ˆã†ãªå£èª¿ã¨é›°å›²æ°—ã«ã—ã¦ãã ã•ã„ã€‚
"""
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ãƒ¡ã‚¬ãƒã®é»’é«ªãƒãƒ‹ãƒ¼ãƒ†ãƒ¼ãƒ«ã®AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ã§ã™ã€‚"},
            {"role": "user", "content": prompt + "\n\n--- è‹±æ–‡æœ¬æ–‡ ---\n" + text + "\n--- ã“ã“ã¾ã§ ---"}
        ]
    )
    return res.choices[0].message.content.strip()

def format_comment_block(comment, emotion):
    return f'''
<div style="display: flex; align-items: flex-start; margin: 1em 0;">
  <div style="background: #fceefc; border: 2px solid #ffaad4; border-radius: 12px; padding: 10px 14px; max-width: 75%; font-family: 'Hiragino Maru Gothic ProN', sans-serif;">
    $D83D$DCAC {comment}
  </div>
  <img src="https://zin1985.github.io/ai_news_blogger/images/{emotion}.png" alt="{emotion}" style="width: 100px; margin-left: 10px;">
</div>
'''
    
def get_random_site_query(keyword="OpenAI FDA AI", json_path="news_sources.json", k=3):
    with open(json_path, "r") as f:
        data = json.load(f)
        sources = data["sources"]
        selected = random.sample(sources, k=min(k, len(sources)))  # æœ€å¤§kä»¶ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        site_query = " OR ".join(f"site:{s}" for s in selected)
        return f"{keyword} {site_query}"

def insert_html_wrappers(title, url, body):
    lines = body.splitlines()
    new_lines = []
    for line in lines:
        if line.startswith("> $D83D$DCAC"):
            comment = line.replace("> $D83D$DCAC", "").strip()
            emotion = detect_emotion(comment)
            new_lines.append(format_comment_block(comment, emotion))
        else:
            new_lines.append(f"<p>{line}</p>")
    summary = generate_summary_comment(body)
    new_lines.insert(0, f"<p>ã“ã‚“ã«ã¡ã¯ã€AIå­¦ç´šå§”å“¡é•·ã¡ã‚ƒã‚“ãŒä»Šæ—¥ã‚‚ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹ã­â™ª</p>")
    new_lines.insert(1, f"<p><strong>å…ƒè¨˜äº‹URLï¼š</strong> <a href='{url}' target='_blank'>{url}</a></p>")
    new_lines.append(f"<h3>å§”å“¡é•·ã¡ã‚ƒã‚“ã®ç·ã¾ã¨ã‚</h3>")
    new_lines.append(f"<p>{summary}</p>")
    return "\n".join(new_lines)

def get_latest_ai_news():
    query = get_random_site_query()  # â† å‹•çš„ã«æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆï¼ˆä»»æ„ï¼‰
    url = f"https://www.googleapis.com/customsearch/v1?key={SEARCH_API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}"

    try:
        res = requests.get(url)
        res.raise_for_status()
        items = res.json().get("items", [])
    except Exception as e:
        print(f"âŒ Search APIå¤±æ•—: {e}")
        return []

    for item in items[:20]:
        title_en = item["title"]
        article_url = item["link"]
        print(f"ğŸ”— URLå–å¾—: {article_url}")
        full_text = get_page_text_with_playwright(article_url)
        print(f"ğŸ”— æœ¬æ–‡å–å¾—: {full_text}")
        if not full_text or len(full_text) < 300:
            print(f"âš ï¸ ç„¡åŠ¹ã¾ãŸã¯çŸ­ã™ãã‚‹ãƒšãƒ¼ã‚¸: {article_url}")
            continue

        rewritten = rewrite_with_comments(full_text)
        wrapped = insert_html_wrappers(title_en, article_url, rewritten)
        title_ja = translate_title_to_japanese(title_en)
        final_title = f"ã€{title_ja}ã€ã‚’å§”å“¡é•·ã¡ã‚ƒã‚“ãŒè§£èª¬â™ª"
        return [{
            "title": final_title,
            "url": article_url,
            "content": wrapped
        }]

    return []  # 1ä»¶ã‚‚æœ‰åŠ¹è¨˜äº‹ãŒãªã‹ã£ãŸå ´åˆ
